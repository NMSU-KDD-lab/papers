
## Tools & links & computing resources
- https://www.connectedpapers.com/: This tool is really helpful for searching for related papers. 
- AI conference dedlines (machine learning, data mining) https://aideadlin.es/?sub=ML,DM
- Computing resource: https://www.xsede.org/
- Deep learning textbook: Dive into Deep Learning https://d2l.ai/

## ASP
- Video by Prof. Schaub at Potsdam https://www.youtube.com/c/potassco-live
- Tutorial by Dr. Son Tran (https://www.cs.nmsu.edu/~hcao/readings/asp-tutorial.pdf)

## Time series classification
1. Xuchao Zhang, Yifeng Gao, Jessica Lin, Chang-Tien Lu: <b>TapNet: Multivariate Time Series Classification with Attentional Prototypical Network</b>>. AAAI 2020 (https://xuczhang.github.io/papers/aaai20_tapnet.pdf)

## Time series clustering
1. Eamonn Keogh,Jessica Lin: Clustering of time-series subsequences is meaningless: implications for previous and future research.(https://link.springer.com/content/pdf/10.1007/s10115-004-0172-7.pdf) 

## Time series segmentation
1. Patrick Schäfer, Arik Ermshaus, Ulf Leser: ClaSP - Time Series Segmentation. (https://www2.informatik.hu-berlin.de/~schaefpa/clasp.pdf)

## Video analysis
1. Yunbo Wang, Zhifeng Gao, Mingsheng Long, Jianmin Wang, Philip S Yu: <b>PredRNN++: Towards A Resolution of the Deep-in-Time Dilemma in Spatiotemporal Predictive Learning</b> Proceedings of Machine Learning Research (PMLR) 2008. (https://proceedings.mlr.press/v80/wang18b.html)

## Incorporating knowledge
1. Russell Stewart, Stefano Ermon: <b>Label-Free Supervision of Neural Networks with Physics and Domain Knowledge</b>. AAAI, 2017. [paper](https://www.aaai.org/Conferences/AAAI/2017/PreliminaryPapers/12-Stewart-14967.pdf) </br> 
This paper works on training a network (f) mapping from inputs to outputs without requiring direct examples of those outputs. It designs a formularization of loss function (g) and regularization term (R). 
2. Zhun Yang, Adam Ishay, Joohyung Lee: NeurASP: Embracing Neural Networks into Answer Set Programming. IJCAI 2020. Pages 1755-1762. https://doi.org/10.24963/ijcai.2020/243.<br/> This is a very good paper on bring NN and ASP together. The use of ASP dramatically changes how to design the loss function. 
4. Sebastian Ruder and Barbara Plank: Strong Baselines for Neural Semi-supervised Learning under Domain Shift. https://arxiv.org/pdf/1804.09530.pdf. <br/>
Good review about semi-supervised learning methods includes tri-training etc.

## Abductive learning
1. Zhi-Hua Zhou: Abductive learning: towards bridging machine learning and logical reasoning. Sci. China Inf. Sci. 62(7): 76101:1-76101:3 (2019)
This is the FIRST paper about abductive learning.

2. 	Wang-Zhou Dai, Qiu-Ling Xu, Yang Yu, Zhi-Hua Zhou:
Bridging Machine Learning and Logical Reasoning by Abductive Learning. NeurIPS 2019: 2811-2822
The knowledge based are represented in first-order logic clauses. 

## Semi-supervised learning
1. Semi-Supervised Learning Literature Survey. This is a TR in 2008. Link: https://pages.cs.wisc.edu/~jerryzhu/pub/ssl_survey.pdf
2. An overview of proxy-label approaches for semi-supervised learning. A blog by SEBASTIAN RUDER, 26 APR 2018. Link: https://ruder.io/semi-supervised/index.html. This blog talks about self-training, tri-training those classifical methods. 

## Power system - security, alarm analysis
1. Yan Xu : A review of cyber security risks of power systems: from static to dynamic false data attacks. Protection and Control of Modern Power Systems volume 5, Article number: 19 (2020). 

## Graph Neural Networks (GNNs)
1. Graph neutral network papers:  https://github.com/thunlp/GNNPapers
2. This is a very classical GNN mode, called Graph neural network transformer. Here is the paper link. https://www.ijcai.org/proceedings/2021/0214.pdf **Masked Label Prediction: Unified Message Passing Model for Semi-Supervised Classification**, published in IJCAI 2021.
3. Graph Neural Network library: https://pytorch-geometric.readthedocs.io/en/latest/
   We can use this library to learn how to practically implement a GNN. 

## Generative Adversarial Networks (GANs), Diffusion models, and Generative AI
- Nan Gao, Hao Xue, Wei Shao, Sichen Zhao, Kyle Kai Qin, Arian Prabowo, Mohammad Saiedur Rahaman, Flora D. Salim:
Generative Adversarial Networks for Spatio-temporal Data: A Survey. CoRR abs/2008.08903 (2020). 
- Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron C. Courville, Yoshua Bengio: Generative adversarial networks. Commun. ACM 63(11): 139-144 (2020). 
- Jinsung Yoon, Daniel Jarrett, Mihaela van der Schaar: Time-series Generative Adversarial Networks. NeurIPS 2019: 5509-5519. 
- Ian J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron C. Courville, Yoshua Bengio: Generative Adversarial Nets. NIPS 2014: 2672-2680.
- Jonathan Ho, Ajay Jain, Pieter Abbeel: Denoising Diffusion Probabilistic Models. NeurIPS 2020. Paper: https://proceedings.neurips.cc/paper/2020/hash/4c5bcfec8584af0d967f1ab10179ca4b-Abstract.html. Code: https://github.com/hojonathanho/diffusion
- Generative Deep Learning (2nd edition) Codebase: https://github.com/davidADSP/Generative_Deep_Learning_2nd_Edition/tree/main/notebooks


## Self-supervised learning
- Part-1 Introduction to Self-Supervised Learning (https://www.youtube.com/watch?v=lW0ZIOyhRic (very high-level))
- Part-2 Introduction to Self-Supervised Learning (https://www.youtube.com/watch?v=j-RSaXzwIHw)
- Yann LeCun @EPFL - "Self-supervised learning: could machines learn like humans?" - https://www.youtube.com/watch?v=7I0Qt…
- Alexei (Alyosha) Efros - Self-Supervised Deep Learning - https://www.youtube.com/watch?v=YhYsv
- Transfer Learning or Self-supervised Learning? A Tale of Two Pretraining Paradigms. Xingyi Yang, Xuehai He, Yuxiao Liang, Yue Yang, Shanghang Zhang, Pengtao Xie (https://arxiv.org/abs/2007.04234) 

## Energy-based models
- Energy-Based Models for Self-Supervised Learning - Yann LeCun (Youtube: https://www.youtube.com/watch?v=BqgnnrojVBI)
- http://courselookup.nmsu.edu

## Interpretable Machine Learning (IML)/Explainable AI (EAI)
- Christoph Molnar, Giuseppe Casalicchio, Bernd Bischl: Interpretable Machine Learning - A Brief History, State-of-the-Art and Challenges. PKDD/ECML Workshops 2020: 417-431. link: https://www.researchgate.net/publication/348959551_Interpretable_Machine_Learning_-_A_Brief_History_State-of-the-Art_and_Challenges
- Shuai Peng, Di Fu, Yong Cao, Yijun Liang, Gu Xu, Liangcai Gao, Zhi Tang:
Compute Like Humans: Interpretable Step-by-step Symbolic Computation with Deep Neural Network. KDD 2022: 1348-1357. link: https://dl.acm.org/doi/10.1145/3534678.3539276
- Md. Mahmudur Rahman, Sanjay Purushotham: Fair and Interpretable Models for Survival Analysis. KDD 2022: 1452-1462. link: https://dl.acm.org/doi/10.1145/3534678.3539259
- Xinli Yu, Zheng Chen, Yuan Ling, Shujing Dong, Zongyi Liu, Yanbin Lu:
Temporal Data Meets LLM - Explainable Financial Time Series Forecasting. CoRR abs/2306.11025 (2023)
- tSNE (https://github.com/shivanichander/tSNE/blob/master/Code/tSNE%20Code.ipynb)

## Trustworthy Machine learning
- Resources for Trustworthy Graph Neural Networks (https://github.com/Radical3-HeZhang/Awesome-Trustworthy-GNNs)
- A website that covers the following aspects of trustworthy ML: explainability, faireness, robust, privacy-preserving, causality (https://www.trustworthyml.org/home)
  
## chatGPT related

## Time Series
- Shaghayegh Gharghabi, Yifei Ding, Chin-Chia Michael Yeh, Kaveh Kamgar, Liudmila Ulanova, Eamonn J. Keogh:
Matrix Profile VIII: Domain Agnostic Online Semantic Segmentation at Superhuman Performance Levels. ICDM 2017: 117-126. link: https://www.cs.ucr.edu/~eamonn/Segmentation_ICDM.pdf

- Effectively Modeling Time Series with Simple Discrete State Spaces (https://arxiv.org/pdf/2303.09489.pdf)

## Anomaly detection
-	Time series anomaly detection (https://paperswithcode.com/task/time-series-anomaly-detection/latest)
-	- Jiehui Xu, Haixu Wu, Jianmin Wang, Mingsheng Long: Anomaly Transformer: Time Series Anomaly Detection with Association Discrepancy. ICLR 2022. (https://openreview.net/pdf?id=LzQQ89U1qm_)
-	Haixu Wu, Tengge Hu, Yong Liu, Hang Zhou, Jianmin Wang, Mingsheng Long: TimesNet: Temporal 2D-Variation Modeling for General Time Series Analysis. ICLR 2023 (https://arxiv.org/pdf/2210.02186.pdf)
-	Lukas Ruff, Robert A. Vandermeulen, Nico Görnitz, Alexander Binder, Emmanuel Müller, Klaus-Robert Müller, Marius Kloft:
Deep Semi-Supervised Anomaly Detection. ICLR 2020 (https://openreview.net/pdf?id=HkgH0TEYwH)

## Self/Semi- supervised learning
- Shikun Liu, Andrew J. Davison, Edward Johns: Self-Supervised Generalisation with Meta Auxiliary Learning. NeurIPS 2019: 1677-1687 (https://arxiv.org/pdf/1901.08933.pdf)

## Practical posts
- Jason Brownlee: SMOTE for Imbalanced Classification with Python by . https://machinelearningmastery.com/smote-oversampling-for-imbalanced-classification/
 

